
#microservices @austingunter: this is the 2nd microservices practitioners summit - there wasn't much from people who did it at scale
#microservices @austingunter: so we wanted to bring in people with that practical experience to talk to you today
#microservices @austingunter: 20% people have 0 microservices in production - the rest are already running microservices
#microservices @austingunter: about 60% of people are interested in resiliency, 
#microservices @varungyan: We start teh day with technology with @mattklein123 and @varungyan
#msvsummit @austingunter: the hashtag for today is #msvsummit - look for that
#msvsummit @mattklein123: I'm Matt Klein, a software engineer at Lyft - I'm going to say how we got to a microservice mesh architecture
#msvsummit @mattklein123: 3-5 years ago Lyft had no SoA - an PHP/Apache monolith with MongoDB as the backing store with 1 load balancer
#msvsummit @mattklein123: PHP/Apache's process per connection model doesn't talk to the load balancer, so we had problems there too
#msvsummit @mattklein123: 2 years ago we had an external LB, a php monolith wiht haproxy to call internal ELBs + a bunch of python services
#msvsummit @mattklein123: we had problems with logging and tracing and understanding which layer something died in
#msvsummit @mattklein123: in SoA now the industry  had tons of languages and frameworks - 3-5 different languages in one deployment
#msvsummit @mattklein123: also, there are per-language libraries for making service calls - Php uses curl, Java uses finagle etc
#msvsummit @mattklein123: we have multiple protocols - http http2 gRPC, databases etc
#msvsummit @mattklein123: we even have multiple infrastructures IaaS CaaS on premise and more
#msvsummit @mattklein123: we een have multiple heterogenous load balancers, and very different observability of stats, tarcing and logging
#msvsummit @mattklein123: we also end up with multiple implementations of retry, circuit breaking and rate limiting, often partial ones
#msvsummit @mattklein123: if you're using all of this stuff in your 5 langs it can be impossible to know what is calling what
#msvsummit @mattklein123: and Authn and Authz is often an afterthought, with no key rotation 
#msvsummit @mattklein123: People do not understand how all these components come together to build a reliable system
#msvsummit @mattklein123: People are feeling a lot of hurt, especially around debugging
#msvsummit @mattklein123: when I joined Lyft people were actually afraid of making service calls as they couldn't know what went wrong
#msvsummit @mattklein123: you have limited visibility into different vendors logging and tracing models, so there is little trust
#msvsummit @mattklein123: existing libraries often have partial implementations of best practices - 
#msvsummit @mattklein123: when we were building Envoy, people would ask why they needed this for retry 
#msvsummit @mattklein123: retry done wrong is the best way to bring down a system 
#msvsummit @mattklein123: if you do have a good answer, you are using a library that locks you into a technology stack
#msvsummit @mattklein123: if you're invested in JVM and you want to use Go services, you need to port the big library over
#msvsummit @mattklein123: if you have a big standard library, upgrading it to a new version can be  a huge pain point
#msvsummit @mattklein123: Robust observability and easy debugging are the most important thing - without that devs don't trust the system
#msvsummit @mattklein123: we have not given people good tools in SoA to do this kind of debugging - so productivity goes down
#msvsummit @mattklein123: when people don't trust the network of service calls, they rebuild monoliths with fixed libraries again
#msvsummit @mattklein123: Envoy wants the network to be transparent to applications, which is really hard
#msvsummit @mattklein123: Envoy is not a library, it is more like nginx or haproxy - it is its own process that is next to each application
#msvsummit @mattklein123: the application talks to Envoy locally, Envoy does the work and moves stuff back to the applicaction
#msvsummit @mattklein123: Envoy is in C++ and is a byte oriented proxy - it can be used for things other than HTTP - stunnel, redis, mongo 
#msvsummit @mattklein123: as well as that L3/L4 filter stack we have an L7 http filter architecture that lets you do header work too
#msvsummit @mattklein123: Envoy was built to be http2 first, but with an http 1.1 bridge - we can proxy gRPC which is http2 based
#msvsummit @mattklein123: we have servoce discovery and active/passive health checking 
#msvsummit @mattklein123: and advance load balancing with timeouts, circuit breaking rate limiting and so on
#msvsummit @mattklein123: we have best in class observability of tracing and stas,
#msvsummit @mattklein123: we have enough features to replace nginx as an edge proxy as well as in service to service mode
#msvsummit @mattklein123: the model we have is many service clusters with an envoy instance with each service, talking to each other
#msvsummit @mattklein123: and also using Envoy to call out to External services and discovery. 
#msvsummit @mattklein123: your service is only aware of your local Envoy, so doesn't change whether in local, dev or production
#msvsummit @mattklein123: Envoy sets up the environment so that dev, staging or production just works - can mix local and cloud abstactly
#msvsummit @mattklein123: we have 2 kinds of edge proxies - one terminating TLS and connecting our internal services,
#msvsummit @mattklein123: but we also use Envoy to proxy between different geographic datacenters
#msvsummit @mattklein123: we have an edge proxy Envoy, which calls the Envoy on our legacy monolith and python and go services
#msvsummit @mattklein123: services don't talk to anything without talking to Envoy - it proxies DynamoDB and MongoDB too
#msvsummit @mattklein123: The way that most service discovery works is fully consistent systems like zookeeper and consul
#msvsummit @mattklein123: 
#msvsummit @mattklein123: 
#msvsummit @mattklein123: but service discovery isn't fully consistent - it changes over time
#msvsummit @mattklein123: if you have a fully consistent problem that can be eventually consistent, make it eventually consistent
#msvsummit @mattklein123: 
#msvsummit @mattklein123: 
#msvsummit @mattklein123: 
#msvsummit @mattklein123: 
#msvsummit @mattklein123: because service discovery is an eventually consistent problem, we designed it that way
#msvsummit @mattklein123: we have about 300 lines of python that checks each server once a minute into a dynamodb
#msvsummit @mattklein123: we have active healtheck checks every 15 seconds, and passive restart on fail
#msvsummit @mattklein123: we trust the active health check more than the discovery service as it is lossy
#msvsummit @mattklein123: if the health check fails we don't route; if the health check fails and discovery shows absent we remove the node
#msvsummit @mattklein123: we have not touched our discovery service in 6 months because it does converge
#msvsummit @mattklein123: people who do use zookeeper and etcd fully consistent systems build eventually consistent discovery on top
#msvsummit @mattklein123: we have multiple service discovery models, including zone aware load balancing - local first then remote
#msvsummit @mattklein123: we can generate dynamic stats, and also do circuit breaking and rate limiting too
#msvsummit @mattklein123: we plan to open source the rate limiting service next week
#msvsummit @mattklein123: we support shadowing so you can fork traffic to a test server
#msvsummit @mattklein123: we ahve built in retries, and inner (1 service) and outer (whole callchain) timeouts
#msvsummit @mattklein123: you can have all these features, but without observability no-one will use them
#msvsummit @mattklein123: by routing all traffic through Envoy, we can produce stats, but also sample entire request chains
#msvsummit @mattklein123: because we have a stable requestID, we can trace and log across multiple systems and servers
#msvsummit @mattklein123: you can have a dashboard that shows all connections between any 2 services
#msvsummit @mattklein123: this lets you look at any 2 hops in the system and how they relate
#msvsummit @mattklein123: for all of the data transited through envoy, you can see the flow of requests through services by default
#msvsummit @mattklein123: our logging system kibana uses the stable request id to connect all the different components and what happened
#msvsummit @mattklein123: a lot of people say 'performance only matters if you are google' - dev time is more important 
#msvsummit @mattklein123: but latency matters, and people don't think about tail latency - the p99+ problem
#msvsummit @mattklein123: we have a lot of tools that make programmers more productive, but much harder to see where time is being spent
#msvsummit @mattklein123: throughput may not be the most important thing, but being abel to reason about where time is spent really matters
#msvsummit @mattklein123: if the service proxy itself has tail latencies that are hard to reason about, you lose the debugging benefits
#msvsummit @mattklein123: you don't want a proxy that adds latency variance and makes your debugging harder
#msvsummit @mattklein123: Lyft has >100 services, >10,000 hosts and >2M RPS - we proxy gRPC, mongodb and dynamodb too
#msvsummit @mattklein123: we sniff the mongodb and dynamodb traffic to generate stats on performance and latency
#msvsummit @mattklein123: we are adding redis soon to reduce outliers
#msvsummit @mattklein123: we are spending more time on outlier detection and rejection
#msvsummit @mattklein123: we are working to standardize load balancing and rate limiting across services
#msvsummit @mattklein123: Envoy has only been open source for about 4 months, but we have a lot of interest already
#msvsummit @mattklein123: we want to build a larger community around Envoy
#msvsummit @mattklein123: you can get the code at lyft.github.io/envoy
#msvsummit @_flynn: when you were getting lyft to switch over to Envoy, what was hard?
#msvsummit @mattklein123: we started incrementally - Envoy as front proxy first. then we added envoy to the monolith, then on mongodb
#msvsummit @mattklein123: we are now fully deployed but it took a year to get concurrent development
#msvsummit q: do you reserve a core for envoy?
#msvsummit @mattklein123: you can do that, but it can make things work. Envoy is non-blocking and parallel. so run 1 thread per core
#msvsummit q: are data piplelines eg spark clusters integrated with Envoy?
#msvsummit @mattklein123: we do use them fro LB but we don't use it directly for Spark
#msvsummit q: can you add filters?
#msvsummit @mattklein123: we don't have any public docs on filters yet, but multiple companies have written them from the code
#msvsummit q: a disadvantage is bringing the work into the envoy team - how do you get it out again?
#msvsummit @mattklein123: that hasn't been a problem so far - "if the word 'car' appears in Envoy we have done it wrong"
#msvsummit @mattklein123: the filtering model is extensible enough that we haven't needed to block on Envoy
#msvsummit q: a lot of systems burn network bandwidth on health checks - do you watch response and health checks separetely?
#msvsummit @mattklein123: active and passive health checks are configurable so you can decide which to use.
#msvsummit @mattklein123: there is perception that active health checking is wasteful, but with plaintext kept-alive http1 it is very low
#msvsummit @mattklein123: we run health checks every 15-30s and it is noise in our traffic graph
#msvsummit @mattklein123: if it does have scale issues we are working on subsetting these so the traffic does't transit so much
#msvsummit @mattklein123: there is no reason that the service discovery system couldn't do health checks too
#msvsummit q: I like to deploy microservices in docker containers, would that work for Envoy?
#msvsummit @mattklein123: we support hot restart in Envoy so it can new code deploy without losing connections-that works fine in containers
#msvsummit @austingunter: we are livestreaming at microservices.com/livestream - follow along there
#msvsummit @varungyan: I'm Varun from Google - I'm here to talk about microservices at Google, but based on our gRPC experience
#msvsummit @varungyan: Stubby is an internal framework at Google for all service to service calls 
#msvsummit @varungyan: we want to bring what we learned from Stubby into the newer open source gRPC
#msvsummit @varungyan: people want Agility and Resilience, and that is why we use microservices,
#msvsummit @varungyan: but we also care about developer productivity - as @mattklein123 said observabilty is key to trust
#msvsummit @varungyan: even a 400ms delay can have a measurable impact on search quality and usability
#msvsummit @varungyan: Stubby was an RPC - Remote Procedure Call - framework written when google started, used for all google services
#msvsummit @varungyan: Stubby is a large framework, and parts of it are being made more open
#msvsummit @varungyan: Google's scale is about 10^10 RPCs per second in our microservices
#msvsummit @varungyan: every Googler defined datatypes and service contarcts and magic around load balancing, monitoring and scaling
#msvsummit @varungyan: making google magic available externally - Borg became Kubernetes; Stubby became gRPC
#msvsummit @varungyan: HTTP1.x/JSON doesn't cut it  at Google scale - stateless, text, loose contracts, TCP per request, nouns-based
#msvsummit @varungyan: a framework with tighter contracts, more efficient on the wire and with language bindings help a lot
#msvsummit @varungyan: when APIs are evolving at different rates, in classic REST this needs a lot of work in polyglot environments
#msvsummit @varungyan: from a pure compute perspective, having text on the wire isn;t most efficient
#msvsummit @varungyan: we needed to establish a lingua franca for strongly typed data - Protocol buffers released in 2003 
#msvsummit @varungyan: declare your data in a common description format, and generate code for any language with fwd/backward compatibility
#msvsummit @varungyan: at Google you are either doing Proto to Proto, or Proto to UI - that's it
#msvsummit @varungyan: protobufs incrementally number fields in order of creation, so you can evolve dat structures over time
#msvsummit @varungyan: the other big protobuf advantage is carrying binary on the wire, giving a 2-3x improvement over JSON
#msvsummit @varungyan: designing for fault tolerance and control is key - sync vs async; deadlines and cancellations; flow control, metadats
#msvsummit @varungyan: different languages default to doing these in different ways, so moving to the core helps
#msvsummit @varungyan: in GRPC we have deadlines, not timeouts - each service will add on time taken and abort if it exceeds deadline
#msvsummit @varungyan: deadlines are expected, but we also need unpredictable cancellations too, when result not needed
#msvsummit @varungyan: with services you need cascaded cancellations that clears all dependent calls too
#msvsummit @varungyan: flow control is not a common occurrence, but matching a fast sender to a slow receiver or vice versa does matter
#msvsummit @varungyan: with gRPC when there are too many requests or responses there is a signal sent to slow down
#msvsummit @varungyan: you can set up service configuration policies that specifies deadlines, LB policy and payload size
#msvsummit @varungyan: the SREs like having this config separately so they can control when things are surging
#msvsummit @varungyan: you don't just need an RPC contract, but also to send metadata for AuthN and trace contexts etc
#msvsummit @varungyan: this metadata helps keep the control flow out of the specific APIs
#msvsummit @varungyan: you want observability and stats - you need a common nomenclature to make sense of large call graphs
#msvsummit @varungyan: you can go to any service endpoint and see a browser dashboard in real time on how much traffic is flwoing
#msvsummit @varungyan: Tracing request through services is key - you can add arbitrary metadata such as client type and track it all
#msvsummit @varungyan: you often have 1 query out f 10,000 that is slow - you want to trace it through the whole call chain
#msvsummit @varungyan: you also want to look at aggregate info to see where the hotspots are
#msvsummit @varungyan: Load Balancing matters, and you need to communicate between the front end, back end and the load balncers
#msvsummit @varungyan: gRPC-lb is moving to a simpler model where the client has a round-robin list of endpoints and the backend models them
#msvsummit @varungyan: gRP is at 1.0 now, and has more platforms and languages now it is in open source
#msvsummit @varungyan: gRPC has service definitions and client side libraries that bridge multiple languages and platforms
#msvsummit @varungyan: http2 is the basis which give streaming and much better startup performance
#msvsummit @varungyan: coming soon: reflection; health checking; automated mock testing
#msvsummit @varungyan: it's at grpc.io and github.com/grpc
#msvsummit @_flynn: how did you switch from Stubby?
#msvsummit @varungyan: that si still happening at google, as a lot of gRPC benefits are already in Stubby
#msvsummit @varungyan: we have to show RoI to service owners inside Google. If you don;t have Stubby, thev alue is clearer
#msvsummit q: how do you do the proto sharing and distribution? one concept of 'user' or every service has one?
#msvsummit q: do you share contracts between services?
#msvsummit @varungyan: every service defines its own, apart from things like tracing and logging 
#msvsummit q: do you generate client and service code from protobufs? does it limit flexibility?
#msvsummit q: yes we generate both; all we generate are stubs i that language - whatever you define is what you get
#msvsummit q: we try to make our APIs as close as possible to the language you are using, so we have fututes in node etc
#msvsummit @christianposta: I'm Christian Posta from Redhat talking managing data inside microservices slides at bit.ly/ceposta-hardest-part
#msvsummit @christianposta: I commit and contribute to apache projects like Camel, ActiveMQ and Kafka
#msvsummit @christianposta: I used to work at a large webscale microservices unicorn company, now I bring that to enterprise
#msvsummit @christianposta: when developers approach Microservices or what was called SoA, they ned to think about more than infrastructure
#msvsummit @christianposta: Adrian Cockcroft warns that you need to copy the Netflix process, not just the results of it
#msvsummit @christianposta: when Enterprise IT approaches this microservices world, there is a mismatch of culture
#msvsummit @christianposta: microservices is about focusing on speed - in terms of being abel to make changes to the system in production
#msvsummit @christianposta: IT in Enterprise has always been seen as a cost center, or as a way of automating paper processes
#msvsummit @christianposta: how do you change a system not designed with this kind of iteration in mind to go fast?
#msvsummit @christianposta: we need to think about managing dependencies between teams as well as services
#msvsummit @christianposta: the difficulty of data is that it is already a model of the world - it hasn't got the human context
#msvsummit @christianposta: even something as simple as a book ends up in multiple models - editions, physical copies, listings by author
#msvsummit @christianposta: each service looks at these things a little bit differently - Domain Driven design helps with this
#msvsummit @christianposta: domain driven design means breaking things into smaller understandable models & defining boundaries around them
#msvsummit @christianposta: enterprise models can end up more complex than purely virtual companies, as the models map to processes
#msvsummit @christianposta: if you write a lot of denormalised data into your databases, you need to plan for the queries you're running
#msvsummit @christianposta: Keep the ACID and relational conveniences as long as you can, but be aware of what they cost
#msvsummit @christianposta: with microservices we're saying "OK, database workhorse, we've go it form here"
#msvsummit @christianposta: saying "a microservice has its own database" sounds very worrying to an enterprise data modeller
#msvsummit @christianposta: microservices means taking concepts of time, delay and failure seriously rather than ignoring them
#msvsummit @christianposta: when we need to distributed writes to maintain consistency, we end up building a transaction manager
#msvsummit @christianposta: it is easy to accidentally build an n+1 problem into your services, and you end up adding extra calls to fix 
#msvsummit @christianposta: with CAP, you can't trade off P, so you have to pick C or A - but there are  lots of consistency models
#msvsummit @christianposta: you don't need strict linear consistency if there is no causal relationship between entities
#msvsummit @christianposta: in real life there is very little strict consistency—think how paper processes propagate updates over time
#msvsummit @christianposta: a sequential consistency is often a good answer - a log or queue to process data in order
#msvsummit @christianposta: when we do this, we have made the replication and indexing that databases did for us an explicit process
#msvsummit @christianposta: Yelp has mySQL Streamer, LinkedIN has Databus, Zendesk has Maxwell - all do this queue to DB model
#msvsummit @christianposta: There's a project debezium.io that captures database changes and streams them in a queue to something like Kafka
#msvsummit @christianposta: I'm going to do a live demo of debezium.io
#msvsummit q: what were you going to demo?
#msvsummit @christianposta: I was going to start up kafka and a mysql database, and connect them with debezium
#msvsummit @christianposta: debezium captures the primary key of the table and uses this to send the before and after changes to the DB
#msvsummit @christianposta: so we can show a change to the database from mysql binlogs in a JSON form in a kafka queue
#msvsummit q: how do we make this work in an environment without arbitrary extentions, like Postgres?
#msvsummit @christianposta: we are working on adding Postgres log support - there was a PR for that recently
#msvsummit q: when you mentioned Domain driven design is CQRS in play?
#msvsummit @christianposta: CQRS is separating different read/write workloads into different data systems 
#msvsummit @christianposta: if your reads are simpler you could use this to transform data into a denormalised system
#msvsummit @austingunter: we've had around 1000 people tuned in to the stream at https://www.microservices.com/livestream/ and we're starting again
#msvsummit @jmholtzman: Microservices are the Future, and always will be
#msvsummit @jmholtzman: xoom.com is a digital remittance company founded 2001, acquired bluekite in 2014, joined paypal 2016
#msvsummit @jmholtzman: remittance is sending money between countries - we go between 56 countries at the moment
#msvsummit @jmholtzman: as a finance company, we have very strict regulatory compliance, both in the US and the 55 other companies
#msvsummit @jmholtzman: we have 16 years of code and 16 years of data to migrate into our microservices
#msvsummit @jmholtzman: we have lots of code and lots of tables, and code that assumes all those tables are joinable
#msvsummit @jmholtzman: xoom was an all java shop, but bluekite made us polyglot - we have many languages and persistence techs now
#msvsummit @jmholtzman: Paypal acquiring us imposed new rules on us, but they also are used to a polyglot environment
#msvsummit @jmholtzman: we wanted to break up the monolith when we hit build time limits on our SQL based infrastructure
#msvsummit @jmholtzman: so a few years ago we started to decouple the teams to reduce the build times
#msvsummit @jmholtzman: we wanted to understand which parts of our stack were the bottlenecks, and scale them appropriately
#msvsummit @jmholtzman: moving to microservices we had to change a lot of programming paradigms and idioms
#msvsummit @jmholtzman: we needed service discovery and monitoring to understand performance
#msvsummit @jmholtzman: we had snowflake code all over the place in our load balancers and deploy path
#msvsummit @jmholtzman: we needed to switch to a unified build and deployment pipeline
#msvsummit @jmholtzman: and we needed to pick apart our databases and define the data ownership and contracts
#msvsummit @jmholtzman: microservices can be a distraction to our engineers - things like circuit breakers and throttles are hard
#msvsummit @jmholtzman: API designs need thought - the N+1 problem needs thinking about, and RPC vs REST adds complexity too
#msvsummit @jmholtzman: with API designs, response code granularity can be a huge issue too - do you pick just some http response codes?
#msvsummit @jmholtzman: Contracts are a key point if you are polyglot coders - you need strong contracts for packaging and metadata
#msvsummit @jmholtzman: we use docker containers for microservices; each service has metadata on the containers and runtime introspection
#msvsummit @jmholtzman: we include things like pager rota in the metadata so you can introspect them to know who to call
#msvsummit @jmholtzman: we can monitor and manage the instances uniformly with this model
#msvsummit @jmholtzman: Having polyglot code can slow you down; if you can stay in a single language and db, do it
#msvsummit @jmholtzman: our service discovery is similar to what Envoy is doing, 
#msvsummit @jmholtzman: we have a custom layer 7 load balancer - zoom.api resolves to the local network
#msvsummit @jmholtzman: so I can hit auth.2.zoom.api and get all the instances with reputation based routing
#msvsummit @jmholtzman: we have a zookeeper backend , but we have an eventually consistent layer on top of it
#msvsummit @jmholtzman: we have a service portal that shows the services and health checks adn routing for each one
#msvsummit @jmholtzman: if you integrate k8s, you need to think about external vs internal service discovery and ip routing
#msvsummit @jmholtzman: for monitoring we initially set up a graphite system and threw lots of data at it, and crashed it with load
#msvsummit @jmholtzman: we were trying to instrument time taken on every call, and this was enough to overwhelm graphite
#msvsummit @jmholtzman: we chose to use http and json for our internal calls between apis
#msvsummit @jmholtzman: a call that involves a post and a write as opoosed to a read, is much more complex to monitor
#msvsummit @jmholtzman: we built a time series for every endpoint and call, and that also created a  lot of traffic 
#msvsummit @jmholtzman: we used the dropwizard monitoring library which gave use gauges and histograms as well as counters
#msvsummit @jmholtzman: we were very worried about performance when we started on this journey - we were worried about extra net traffic
#msvsummit @jmholtzman: we spent a lot of time instrumenting our code before we made any changes, and I recommend that
#msvsummit @jmholtzman: we improved the throughput of our service dramatically, primarily because of the shift to accurate monitoring
#msvsummit @jmholtzman: this helped us reduce contention over shared resources, despite making more RPCs overall
#msvsummit @jmholtzman: the latency distribution is wider now - we adjusted latency sensitive APIs to be deployed nearby
#msvsummit @jmholtzman: infrastructure as code matters - TDD isn't just fro code, write tests for deployment too
#msvsummit @jmholtzman: don't treat deployment code and networking configurations as special - they all need tests too
#msvsummit @jmholtzman: by standardising app packaging, we can have contracts for deployment too
#msvsummit @jmholtzman: we use git-flow for new features, with a container per branch using docker-flow, automated+ self service deployments
#msvsummit @jmholtzman: by standardising deployment pipeline, we can have a portal to enable PMs to deploy versions withtout ops
#msvsummit @jmholtzman: data ownership is hardest  - we are eliminating cross-domain joins and adding apis to wrap them
#msvsummit @jmholtzman: we have about 100 different services now
#msvsummit @jmholtzman: the key is to measure everything, and be prepared to scale monitoring to cope
#msvsummit @jmholtzman: application packaging contracts and delivery pipelines are mandatory
#msvsummit @jmholtzman: staff a tooling team to build, test and deployment automation and bring in network ops
#msvsummit @jmholtzman: although our monolith is still partly there, the infrastructure and cultue has improved everything
#msvsummit @_flynn: what was the challenge you were least expecting?
#msvsummit @jmholtzman: the metric explosion caught us off guard - be prepared fro that
#msvsummit q: how do you do integration testing when you have a large number of services?
#msvsummit q: we have ~200 clusters we can spinup and down in both amazon and our data center
#msvsummit q: the other integration testing is to create mocks so you can run those. also can run containers locally and route to cloud
#msvsummit @jmholtzman: for us, anyone who writes code can't touch the production network and vice versa - this is not very DevOps
#msvsummit q: sounds like you built togetehr multiple solutions. how do you monitor end to end?
#msvsummit @jmholtzman: for our java applications we wrote a wrapper applications to give tracing for free
#msvsummit @jmholtzman: calico gives us the ability to have routable ip addresses per pod, which helps us with monitoring the whole system
#msvsummit @jmholtzman: we found that we had 2 services that constantly want to make joins, so they need to be one service not two 
#msvsummit q: you mentioned that this was a cultural change, what was the impact?
#msvsummit @jmholtzman: our product managers have been very customer focused. The big change was getting them to think about SLA and contracts as well
#msvsummit q: were there challenges in batch jobs?
#msvsummit @jmholtzman: putting the batch jobs with the domain that owns them makes more sense
#msvsummit Rafi: I'm Rafi Schloming from datawire - we founded it in 2014 to focus on microservcie from a distributed systems background
#msvsummit Rafi: I participated in every version of AMQP and had built lots of distributed systems with them, so I thought it would be easy
#msvsummit Rafi: I wanted to look back at my learning about microservices
#msvsummit Rafi: wikipedia isn't helpful here - "there is no industry consensus" "Processese that communicate" "enforce modular naturally"
#msvsummit Rafi: there are a lot of good essays about microservices, but also a lot of horror stories of going wrong
#msvsummit Rafi: the 3 aspects I want to cover is the technology, the process and the people
#msvsummit Rafi: we learned from experts, from bootstrapping ourselves and from people migrating to microservices from many origins
#msvsummit Rafi: 3 years ago it was very technically focused - a network of small services, hoping it would make better abstractions
#msvsummit Rafi: we read every story of microservices, went to conferences, started the summit ourselves to share the ideas
#msvsummit Rafi: the people picture: everyone  has a developer happiness/tooling/platform team and a service team that build features
#msvsummit Rafi: technically we saw a control plane for instrumenting the services , the services and a traffic layer
#msvsummit Rafi: it's a lot of work to build a control plane, so we decided to provide that as a service for the teams
#msvsummit Rafi: so we ingest interesting application events - start, stop, heartbeat. log these and register services; transform & present
#msvsummit Rafi: we were building a classic data processing pipe line of ingest, write source of truth, transform and present
#msvsummit Rafi: for version 1 we built discovery - highly available, low throughput and latency; low complexity and able to survive restart
#msvsummit Rafi: we started with vert.x and hazelcast and websockets with smart clients
#msvsummit Rafi: for version2 we added tracing - high throughput , a bit higher latency was OK
#msvsummit Rafi: version 3 we added persistence for tracing by adding elastic search
#msvsummit Rafi: this was the 1st hint of pain - we had to reroute data pathways and had coupled changes, and this gave a big scary cutover
#msvsummit Rafi: v4: we added persistence for discovery, using postgres for persistence, which was another scary cutover -lets fix our tools
#msvsummit Rafi: Deployment was hard. we had tried docker, but that was hard to bootstrap; kubernetes required google not amazon
#msvsummit Rafi: we redesigned our deployment system to define the system in git to bootstrap from scratch
#msvsummit Rafi: this meant we could use minikube locally with postgres and redis in docker images
#msvsummit Rafi: and then spin this up to production running in amazon with our own kubernetes cluster
#msvsummit Rafi: we built tooling to make this work across the different dev and deployment environment
#msvsummit Rafi: did we just reinvent DevOps the hard way? we were thinking about operational factors, we built a service not a server
#msvsummit Rafi: rather than a Service Oriented Architecture, we had a Service Oriented Development
#msvsummit Rafi: Architecture has lots of upfront thinking and a slow feedback cycle. Development is more incremental
#msvsummit Rafi: Development is frequent small changes with quick feedback and measureable impact at each step
#msvsummit Rafi: so microservices are a developmental methodology for systems, rather than an architectural one
#msvsummit Rafi: small frequent changes and rapid feedback and visibility are given for a codebase, but harder for a whole system
#msvsummit Rafi: so microservices are a way to gather rapid feedback - not just tests but live measurement
#msvsummit Rafi: instead of build - test -deploy we want build - test - assess impact - deploy
#msvsummit Rafi: so measure throughput, latency, and availability measured as error rate
#msvsummit Rafi: the experts model of canary testing, circuit breakers and so on are ways of making sense of a running system
#msvsummit Rafi: Technical: small services; scaffolding for changes Process: service oriented development People: tools and services
#msvsummit Rafi: working with people migrating gave us much more information
#msvsummit Rafi: migration is about people. Picking a technical stack for the entire Org is hard; refactoring has lots of org friction
#msvsummit Rafi: creating an autonomous team to tackle a problem in the form of a service is much easier
#msvsummit Rafi: some organisations hit a sticking point, others didn't slow down
#msvsummit Rafi: the way to think about microservices is in dividing up the work: build features (dev) Keep it running (ops)
#msvsummit Rafi: you can't easily divide along these lines - new features make it unstable. devops stops misaligned incentives
#msvsummit Rafi: microservices divides up the work  - a big app made of smaller ones, that are easier to keep running, aligning incentives
#msvsummit Rafi: if you think about microservices an an architecture you forget about the operational side of keeping them running
#msvsummit Rafi: the easy way: start with principles of People and Process, and use that to select the technology
#msvsummit @_flynn: how would you boil this down to one statement?
#msvsummit Rafi: start with the people and think how to divide up the work first, let that lead to the technical perspective
#msvsummit q: how much time did you spend on research and things that didn't make production?
#msvsummit Rafi: it's hard to quantify that time spent - it ended up as a fragmented and incremental view
#msvsummit q: do you see Conways law affecting your team size?
#msvsummit Rafi: yes, there is an impact there - trying to fit the information into the picture
#msvsummit Rafi: that the shape of the team drives he shape of the technology is true, but physics pushes the other way
#msvsummit @nicbenders: I'm Nic Benders, chief architect at New Relic, talking about Engineering and Autonomy in the Age of Microservices
#msvsummit @nicbenders: I want to talk about that you can accomplish in an engineering org with microservices
#msvsummit @nicbenders: New Relic started out with a data collection service and a data display service that started out micro and grew
#msvsummit @nicbenders: we now have over 300 services in out production environment
#msvsummit @nicbenders: Conway's law always is in play - our production environment reflects the communications & dependecies between teams
#msvsummit @nicbenders: Conway's law is about how teams communicate, not the actual org chart. It's the edges, not the nodes that matter
#msvsummit @nicbenders: Conway: Organisations are constrained to produce designs that are copies of the communication structures of the org
#msvsummit @nicbenders: microservices is meant to define teams around each service - that is the core 
#msvsummit @nicbenders: componetisation via teams organised around business capabilities - products not projects so long term ownership
#msvsummit @nicbenders: smart teams and dumb communication pipes - use a lightweight tool like a wiki or blog
#msvsummit @nicbenders: durable full-ownership teams organised on business capabilities w authority to choose tasks & complete independently
#msvsummit @nicbenders: reduce central control - emphasising information flow from the center and decision making at the edge
#msvsummit @nicbenders: Eliminate dependencies between teams as each dependency is an opportunity to fail
#msvsummit @nicbenders: having a re-org seems like a good idea, but it doesn't really work well if you just rename and change reports
#msvsummit @nicbenders: what if we look at an org structure as an engineering goal? Optimize for agility -not utilisation of a team
#msvsummit @nicbenders: if you optimize teams for efficient usage of the team, you make sure that they have a backlog to keep busy
#msvsummit @nicbenders: what we need are short work queues and decision making at the edge
#msvsummit @nicbenders: as chief architect, I know far less than about the domain than the engineer working on the problem does
#msvsummit @nicbenders: at new relic, we're data nerds. We should use data to make our changes, not VPs in offsites
#msvsummit @nicbenders: the most important thing in our org change is to break our dependencies betwen teams
#msvsummit @nicbenders: we drew the nodes as teams and the edges as dependencies, and simplified universal ones
#msvsummit @nicbenders: we proposed some much simpler dependency diagrams, with fewer, stronger teams with full ownership
#msvsummit @nicbenders: in a full stack team, you are missing a business ownership component, so we added PMs and tech leads for internal
#msvsummit @nicbenders: for the team to work it needs more T-shaped people. with depth in one area, and breadth across others
#msvsummit @nicbenders: we abolished architecture reviews, and made each team stand alone and own its decisions
#msvsummit @nicbenders: we decided to allow team self-selection, as people know their skills better than we do
#msvsummit @nicbenders: we put out all the jobs needed by the department and the engineers pick the ones to do. This is harder than it looks
#msvsummit @nicbenders: Managers really didn't like this. Managers tend to follow instructions anyway, so it worked.
#msvsummit @nicbenders: Engineers didn't like it either. They didn't trust us -they thought there would be fewer jobs that they wanted
#msvsummit @nicbenders: they also worried that they would pick the wrong thing, or that the teams would gel without managers
#msvsummit @nicbenders: We almost backed down. But we had to get the teams to self correct. We had failed to empathize with their concerns
#msvsummit @nicbenders: we had to communicate over and over that this wasn't a stealth layoff or a job fair, but we would take care of them
#msvsummit @nicbenders: we were not shifting the burden of being responsible to the employees but making sure we still looked after them 
#msvsummit @nicbenders: we defined the teams & the skills they needed, not in terms of positions & got everyone in a room to find new teams
#msvsummit @nicbenders: at this point we had at least made it clear that there were other teams that you could move to
#msvsummit @nicbenders: about a third of the people there did switch teams - lots of new teams formed from scratch
#msvsummit @nicbenders: working agreements per team were defined as "we work together best when…" for them to fill in
#msvsummit @nicbenders: the insights team picked Continuous Deployment Weekly demos and Retros, and Mob Programming 
#msvsummit @nicbenders: Mob Programming is like pair programming, but with 6 people sitting round the computer with 1 typing - huge agility
#msvsummit @nicbenders: this reorg really worked - we shipped far more this year than expected, because they worked faster on what mattered
#msvsummit @nicbenders: Teams understood their technical remit, but not what the boundaries were - we were used to side projects
#msvsummit @nicbenders: we wrote a rights and responsibilities document - teams write own Minimal Marketable Features, but must listen too
#msvsummit @nicbenders: maybe you aren't going to try a 6-month re-org, but there are takeaways
#msvsummit @nicbenders: you hired smart engineers - trust them. We didn't do this with MBAs and VPs but with the teams themselves
#msvsummit @nicbenders: my presentation is up at http://nicbenders.com/presentations/microservices-2017/ and you can tweet me with comments
#msvsummit @nicbenders: the main thing I was worried about tactically was making 300 people fit into 300 jobs and teams would not fit
#msvsummit @nicbenders: there were a few people in critical roles that we had to keep in place, and we really owe them
#msvsummit q: what does a manager do in this kind of team?
#msvsummit @nicbenders: regardless of org structure, managers need to look after their team and the teams' careers
#msvsummit @nicbenders: we have spent more time encouraging the embedded PM to work with the team since
#msvsummit q: what happened giving the teams total control of technology?
#msvsummit @nicbenders: I sometimes think "that's not the best tech really, it's just some hacker news thing" but if they can go faster…
#msvsummit @nicbenders: we have some constraints - we are container based, but it you need, say, an Elixir agent you have to build that too
#msvsummit q: you mentioned 6 months - was that how long it took to settle down?
#msvsummit @nicbenders: within the 1st month there were teams up and running, but the experience varied. 
#msvsummit q: did the managers go and find new teams, or were they fixed?
#msvsummit @nicbenders: in general managers were the core of the team, and engineeers moved to them, which may be why they were unhappy
#msvsummit q: how did this map to employee performance management?
#msvsummit @nicbenders: we did reset the performance history, and had a lot of success, and a modest turnover too close to annual average
#msvsummit q: who owns the space between the teams? how do they call each others code?
#msvsummit @nicbenders: communication is owned by the architecture team, and we have cross-functional groups for each language etc
#msvsummit @nicbenders: we have a product council to say what the key products and boundaries are  but no the detail which team does 
#msvsummit @nicbenders: we mapped every product and service, including external ones, before we moved everyone
#msvsummit @nicbenders: we had a 2 week transition to make the pager rotation handovers and deploy work.
#msvsummit q: after this do the people feel they need another team change? how often do you redo this?
#msvsummit @nicbenders: it was such a production that we would rather have a continuous improvement rather than an annual scrambling
#msvsummit @nicbenders: we have a quarterly review per team, but we want to make it possible for internal transfers be low friction
#msvsummit @susanthesquark: I'm Susan Fowler here to talk about Microservice Standardization
#msvsummit @susanthesquark: I stared off thinking I would do particle physics forever, but there are no jobs in physics
#msvsummit @susanthesquark: I worked on the Atlas experiment at CERN, and then went to Uber to work on their 1000 microservices
#msvsummit @susanthesquark: there were some microservices that had lots of attention, but we were the SRE microservices consulting team
#msvsummit @susanthesquark: I also wrote a book called Production-Ready Microservices - there is a free summary version online
#msvsummit @susanthesquark: every microservice orgnaisation hits 6 challenges at scale
#msvsummit @susanthesquark: challenge 1: Organisation siloing and sprawl - microservices developers become like services and are very siloed
#msvsummit @susanthesquark: unless you standardise operational models and communication, they won't be abel to move teams
#msvsummit @susanthesquark: when you have too many microservices, you can't distribute ops easily, so the devs are fighting ops battles too
#msvsummit @susanthesquark: challenge 2: More ways to fail - more complex systems have more ways to fail. don't make each service a SPOF
#msvsummit @susanthesquark: challenge 3: competition for resources - a microservice ecosystem competes for hardware and eng resources
#msvsummit @susanthesquark: challenge 4: misconceptions about microservices - wild west; free reign; any lang; any db; silver bullet
#msvsummit @susanthesquark: myth: engineers can build a service that does one thing extraordinarily well, and do anything they want for it
#msvsummit @susanthesquark: a team will say "we heard cassandra is really great, we'll use that" the answer: "you are taking on the ops too"
#msvsummit @susanthesquark: microservices are a step in evolution, not a way out of problems of scale
#msvsummit @susanthesquark: challenge 5: technical sprawl and technical debt - favorite tools, custom scripts; custom infra; 1000 ways to do
#msvsummit @susanthesquark: people will move between teams and leave old services running  - no-one wants to clean up the old stuff
#msvsummit @susanthesquark: Challneg 6: inherent lack of trust - complex dependency chains that you can't know are reliable
#msvsummit @susanthesquark: you don't know that your dependencies will work, or that your clients won't overload you; no org trust
#msvsummit @susanthesquark: no way of knowing that the microservices can be trusted with production traffic
#msvsummit @susanthesquark: microservices aren't always as isolated from each other as their teams are isolated
#msvsummit @susanthesquark: The way around these challenges is standardization. Microservices aren't isolated systems
#msvsummit @susanthesquark: you need to standardize hardware (servers, dbs) Communication (network, dbs, rpc) app platform (dev tools, logs)
#msvsummit @susanthesquark: the microservices and service specific configs should be above these 3 standard levels
#msvsummit @susanthesquark: a microservice has upstream clients; a database and message broker; and downstream dependencies too
#msvsummit @susanthesquark: the solution is to hold microservices to high architectural, organisational and operational standards
#msvsummit @susanthesquark: determining standards on a microservice by microservice basis doesn't establish cross-team trust, adds debt
#msvsummit @susanthesquark: global standardization company wide - must be global and general; hard to determine from scratch & apply to all
#msvsummit @susanthesquark: the way to approach standards is to think of a goal - the best one to start with is availability
#msvsummit @susanthesquark: availability is a bit high level, map that to stability, reliability, scalability, performance, monitoring, docs
#msvsummit @susanthesquark: microservices increase developer velocity, so more changes, deployments, instability - need deploy stability 
#msvsummit @susanthesquark: if you have development, canary, staging, production deployment pipeline, it should be stable at the end
#msvsummit @susanthesquark: Scalability and Performance - need to scale with traffic and not compromise avaiabiliity
#msvsummit @susanthesquark: fault tolerance and catastrophe preparedness - they need to withstand internal and external failure modes
#msvsummit @susanthesquark: every failure mode you can think of - push it to that mode in production and see how it does fail in practice
#msvsummit @susanthesquark: Monitoring and Documentation standards mean knowing the state of the system, and very good logging to see bugs
#msvsummit @susanthesquark: Documentation removes technical debt-  organisational level understanding of it matters
#msvsummit @susanthesquark: implementing standardisation needs buy-in from all org levels; know production readiness reqs and make culture
#msvsummit @susanthesquark: my free guide is http://www.oreilly.com/programming/free/microservices-in-production.csp and my book is at http://shop.oreilly.com/product/0636920053675.do 
#msvsummit @susanthesquark: when you have a set of answers to the standards  for the whole company, it makes it all easier
#msvsummit @_flynn: how long did it take to fix all the services?
#msvsummit @susanthesquark: It's still going on; we started with the most urgent services and helped them understand what was around tem
#msvsummit q: you mentioned proper documentation - how do you keep up with code changes?
#msvsummit @susanthesquark: that's a good question - keep docs to what is actually useful and relevant. Describe arch and endpoints
#msvsummit @susanthesquark: documentation isn't a post mortem for an outage, but an understanding of what works
#msvsummit q: is slicing up the layers a contradiction to devops?
#msvsummit @susanthesquark: the microservices team should be on call for their own services' outages but need to be both?